---
title: "Mapping Observations"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
---

In this article we'll walk through how to create various types of maps of the observations downloaded with `naturecounts` to get a sense of the spatial distribution.

> The following examples use the "testuser" user which is not available to you. 
> You can quickly [sign up for a free account](https://naturecounts.ca/nc/default/register.jsp)
> of your own to access and play around with these examples. Simply replace
> `testuser` with your own username.

## Setup

To do so we're going to use the following packages:

```{r, message = FALSE}
library(naturecounts)
library(sf)
library(rnaturalearth)
library(ggmap)
library(dplyr)
library(tidyr)
library(mapview)
```

First we'll use download some data:

```{r}
house_finches <- nc_data_dl(species = 20350, region = list(statprov = "AB"), 
                            username = "testuser", info = "nc_tutorial")
head(house_finches)
```

## Simple Maps
The quickest way to look at the spatial distribution is probably to use Stamen maps through the `ggmap` package.

First let's get an idea of how many distinct points there are (often multiple observations are recorded for the same location).
```{r}
nrow(house_finches)

select(house_finches, longitude, latitude) %>%
  distinct() %>%
  nrow()
```

So we have `r nrow(unique(house_finches[, c("longitude", "latitude")]))` sites for `r nrow(house_finches)` observations.

Next let's convert our data to spatial data so we can extract the spatial extent. Note that we're using CRS EPSG code of 4326 because that's reflects unprojected, GPS data in lat/lon. First we omit `NA`s.
```{r}
house_finches <- drop_na(house_finches, "longitude", "latitude")
house_finches_sf <- st_as_sf(house_finches, 
                             coords = c("longitude", "latitude"), crs = 4326)
```

We can extract the spatial extent (**b**ounding **box**) with the `st_bbox()` function.

```{r}
st_bbox(house_finches_sf)
```

Now we're ready to make a map of the distribution of observations. First we get the baselayer map.
```{r}
map <- get_stamenmap(bbox = as.numeric(st_bbox(house_finches_sf)), zoom = 5)
```

Now we can add our observations. Note that for `ggmap`, we'll use non-sf data frame.
```{r}
ggmap(map) + 
  geom_point(data = house_finches, aes(x = longitude, y = latitude))
```

Let's count our observations for each site.
```{r}
ggmap(map) + 
  geom_count(data = house_finches, aes(x = longitude, y = latitude))
```

## Interactive Maps
If we want to get fancy we can also create interactive maps using the `mapview` packages (see also the [`leaflet` for R package](https://rstudio.github.io/leaflet/)).
```{r, eval = FALSE}
mapview(house_finches_sf, zcol = "survey_year", at = seq(1965, 2005, by = 10),
        map.types = "Esri.WorldImagery")
```

## More Complex Maps

For more complex, or detailed maps, we can use a variety of spatial data files to layer our data over maps of the area.

For this we'll get some outlines of Canada and it's Provinces and Territories from `rnaturalearth`.

```{r}
canada <- ne_states(country = "canada", returnclass = "sf") %>%
  st_transform(3347)

ggplot() +
  theme_bw() +
  geom_sf(data = canada)
```


Let's add our observations (note that the data are transformed to match the projection of the first layer, here the `canada` data).
```{r}
ggplot() +
  theme_bw() +
  geom_sf(data = canada) +
  geom_sf(data = house_finches_sf, size = 0.5)
```

We can also focus on Alberta

```{r}
ab <- filter(canada, name == "Alberta")

ggplot() +
  theme_bw() +
  geom_sf(data = ab) +
  geom_sf(data = house_finches_sf, size = 0.5)
```

Perhaps we should see how many of these observations were made in parks. 

First we'll download and extract the Park shapefiles available from the [Alberta Parks](https://www.albertaparks.ca/albertaparksca/library/downloadable-data-sets/) website.

```{r, echo = FALSE, eval = !file.exists("vignettes/articles/article_files/Parks_Protected_Areas_Alberta.shp")}
# Run if don't have shapefile
download.file(url = "https://www.albertaparks.ca/media/2941843/parks_and_protected_areas_alberta.zip",
              destfile = "vignettes/articles/article_files/alberta_parks.zip")
unzip("vignettes/articles/article_files/alberta_parks.zip", 
      exdir = "vignettes/articles/article_files/")
```

```{r, eval = FALSE}
url <- "https://www.albertaparks.ca/media/2941843/parks_and_protected_areas_alberta.zip"
download.file(url = url)
unzip("parks_and_protected_areas_alberta.zip")

parks <- st_read("Parks_Protected_Areas_Alberta.shp")
```

```{r echo = FALSE}
parks <- st_read("vignettes/articles/article_files/Parks_Protected_Areas_Alberta.shp")
```

Add this layer to our plot.

```{r}
ggplot() +
  theme_bw() +
  geom_sf(data = ab) +
  geom_sf(data = parks, colour = "darkgreen", fill = "forestgreen") +
  geom_sf(data = house_finches_sf, size = 0.5)
```

Well it's actually a bit difficult to tell, there are lots of small parks! 

To solve this problem, we can merge our observations with the parks and plot those inside parks separately from those outside parks.

First we'll transform our observation data to match the CRS of `parks`, then we'll join the park information to our observations, based on whether the observations overlap a park polygon (by default this is a left join), and finally we'll create a new column `outside_park` that is a category for out or in the park, based on whether the observation was joined to a park name (`OC_NAME`).

```{r}
house_finches_sf <- house_finches_sf %>%
  st_transform(st_crs(parks)) %>%
  st_join(parks) %>%
  mutate(outside_park = if_else(is.na(OC_NAME), "Outside Park", "Inside Park"))
```

And now we can see that there are quite a few, if not more, observations outside of parks than in.
```{r}
ggplot() +
  theme_bw() +
  geom_sf(data = ab) +
  geom_sf(data = parks, colour = "darkgreen", fill = "forestgreen") +
  geom_sf(data = house_finches_sf, size = 1) +
  facet_wrap(~outside_park)
```

We might also be interested in observations over time.

First we'll bin our yearly observations
```{r}
house_finches_sf <- mutate(house_finches_sf, 
                           years = cut(survey_year, 
                                       breaks = seq(1960, 2010, 10), 
                                       labels = seq(1960, 2000, 10), right = FALSE))
```

We'll also want to see how many sample years there are per decade.
```{r}
years <- house_finches_sf %>%
  group_by(years) %>%
  summarize(n = length(unique(survey_year)), .groups = "drop")
```


Now we can see how House Finch observations change over the years

```{r}
ggplot() +
  theme_bw() +
  geom_sf(data = ab) +
  geom_sf(data = parks, colour = "darkgreen", fill = "forestgreen") +
  geom_sf(data = house_finches_sf, size = 1.5) +
  geom_sf_text(data = years, x = 4427134, y = 2965275, hjust = 0, vjust = 1, 
               aes(label = paste0("n = ", n))) +
  facet_wrap(~years)
```

## Presence/Absence

We can also use some of the `naturecounts` helper functions to create presence/absence maps. 

Here we download data from the `RCBIOTABASE` collection, make sure to keep only observations where all species and the location were reported, create a new `presence` column which is either TRUE, FALSE, or NA for each sampling event. Finally we use the `format_zero_fill()` function to fill in sampling events where cardinals (`species_id` 19360) were not detected (presence would then be 0).

```{r}
cardinals <- nc_data_dl(collection = "RCBIOTABASE", username = "testuser", 
                        info = "nc_tutorial")

cardinals_zf <- cardinals %>%
  filter(AllSpeciesReported == "Yes", !is.na(latitude), !is.na(longitude)) %>%
  group_by(species_id, AllSpeciesReported, SamplingEventIdentifier, latitude, longitude) %>%
  summarize(presence = sum(as.numeric(ObservationCount)) > 0, .groups = "drop") %>%
  format_zero_fill(species = 19360,
                   by = "SamplingEventIdentifier",
                   extra_event = c("latitude", "longitude"),
                   fill = "presence")

head(cardinals_zf)
```

Now that we have our presence/absence data for cardinals, we can create a map.
```{r}
map <- st_as_sf(cardinals_zf, coords = c("longitude", "latitude")) %>%
  st_bbox() %>%
  as.numeric() %>%
  get_stamenmap(bbox = ., zoom = 8)

ggmap(map, base_layer = ggplot(data = cardinals_zf)) +
  geom_count(alpha = 0.75,
             aes(x = longitude, y = latitude, colour = factor(presence))) +
  scale_colour_manual(name = "Presence/Absence", values = c("yellow", "purple"), 
                      labels = c("1" = "Present", "0" = "Absent")) +
  scale_size_continuous(name = "Number of Sampling Events", range = c(1, 20)) +
  labs(title = paste0("Presence/Absence of Cardinals in the RCBIOTABASE collection"))
```


## See Also

- [Using spatial data to filter observations](region-spatial.html)
- [Exploring regional filters](../region-areas.html)
